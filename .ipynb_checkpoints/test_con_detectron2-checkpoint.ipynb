{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to restart your runtime prior to this, to let your installation take effect\n",
    "# Some basic setup\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from imageTools import imageTool\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.visualizer import VisImage\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "im = cv2.imread(\"/home/asung/detImage/h.jpg\")#/home/asung/detImage/i1.jpeg\n",
    "print(im.shape)\n",
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "cfg.merge_from_list(['MODEL.DEVICE','cpu'])\n",
    "# Find a model from detectron2's model zoo. You can either use the https://dl.fbaipublicfiles.... url, or use the detectron2:// shorthand\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"\n",
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=15, image_height=480, image_width=640, fields=[pred_boxes, scores, pred_classes, pred_masks]) <class 'detectron2.structures.instances.Instances'> \n",
      "\n",
      "\n",
      "class:  torch.Size([15]) \n",
      " tensor([17,  0,  0,  0,  0,  0,  0,  0, 25,  0, 25, 25,  0,  0, 24]) \n",
      "\n",
      "boxes:  torch.Size([15, 4]) \n",
      " Boxes(tensor([[126.6035, 244.8977, 459.8291, 480.0000],\n",
      "        [251.1083, 157.8127, 338.9731, 413.6379],\n",
      "        [114.8496, 268.6864, 148.2351, 398.8111],\n",
      "        [  0.8217, 281.0327,  78.6072, 478.4210],\n",
      "        [ 49.3954, 274.1229,  80.1545, 342.9808],\n",
      "        [561.2249, 271.5816, 596.2755, 385.2552],\n",
      "        [385.9072, 270.3125, 413.7130, 304.0397],\n",
      "        [515.9295, 278.3744, 562.2792, 389.3803],\n",
      "        [335.2410, 251.9167, 414.7491, 275.9375],\n",
      "        [350.9300, 269.2060, 386.0984, 297.9081],\n",
      "        [331.6292, 230.9996, 393.2759, 257.2009],\n",
      "        [510.7349, 263.2656, 570.9865, 295.9194],\n",
      "        [409.0841, 271.8646, 460.5582, 356.8722],\n",
      "        [506.8766, 283.3257, 529.9404, 324.0392],\n",
      "        [594.5663, 283.4820, 609.0577, 311.4124]])) \n",
      "\n",
      "scores:  torch.Size([15]) \n",
      " tensor([0.9997, 0.9957, 0.9915, 0.9882, 0.9861, 0.9840, 0.9769, 0.9716, 0.9062,\n",
      "        0.9037, 0.8870, 0.8575, 0.6592, 0.5899, 0.5767]) \n",
      "\n",
      "masks:\n",
      " <class 'torch.Tensor'> torch.Size([15, 480, 640]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(outputs[\"instances\"],type(outputs[\"instances\"]),\"\\n\\n\")\n",
    "print(\"class: \",outputs[\"instances\"].pred_classes.shape,\"\\n\",outputs[\"instances\"].pred_classes,\"\\n\")\n",
    "print(\"boxes: \",outputs[\"instances\"].pred_boxes.tensor.shape,\"\\n\",outputs[\"instances\"].pred_boxes,\"\\n\")\n",
    "print(\"scores: \" ,outputs[\"instances\"].scores.shape ,\"\\n\",outputs[\"instances\"].scores,\"\\n\")\n",
    "print(\"masks:\\n\",type(outputs[\"instances\"].pred_masks),outputs[\"instances\"].pred_masks.shape,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = outputs[\"instances\"].pred_boxes.tensor\n",
    "pred = outputs['instances'].pred_classes\n",
    "masks = outputs[\"instances\"].pred_masks\n",
    "scores = outputs[\"instances\"].scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([14229, 36304,  4965, 16053,  2284,  4283,  1299,  5577,   260,  1344,\n",
      "          228,   180,  3057,   501,    19])\n"
     ]
    }
   ],
   "source": [
    "idx,poslist = imageTool.get_weight(outputs,im)\n",
    "x_s,y_s,x_d,y_d = boxes[idx]\n",
    "print(poslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conlist=imageTool.getconInstances(boxes,idx,poslist)\n",
    "conlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgeSearch(mask,x_s,x_d,flag):\n",
    "    maskArry = torch.where(mask == True)[0]\n",
    "    if maskArry.size() == torch.Size([0]):\n",
    "        return -1\n",
    "    if flag :\n",
    "        src = maskArry[0]+1\n",
    "    else : src = maskArry[-1]-1\n",
    "    return src\n",
    "\n",
    "\n",
    "def expand(masks,size,y_s,y_d,x_s,x_d):\n",
    "    mask = masks.clone()\n",
    "    masktemp = masks.clone()\n",
    "    y_s,y_d,x_s,x_d = int(y_s),int(y_d),int(x_s),int(x_d)\n",
    "    for i in range(y_s,y_d):\n",
    "        leftx = edgeSearch(masktemp[i],x_s,x_d,True)\n",
    "        rightx = edgeSearch(masktemp[i],x_s,x_d,False)\n",
    "        if leftx == -1 :\n",
    "            continue\n",
    "        mleft = max(leftx-size,0)\n",
    "        mright = min(rightx+size,mask.shape[1])\n",
    "        mask[i][mleft:leftx] = True    #왼쪽으로 쭉\n",
    "        mask[i][rightx:mright] = True  #오른쪽으로 쭉\n",
    "\n",
    "    masktemp = masks.clone()\n",
    "    for i in range(x_s,x_d):\n",
    "        upy = edgeSearch(masktemp.T[i],y_s,y_d,True)\n",
    "        downy = edgeSearch(masktemp.T[i],y_s,y_d,False)\n",
    "\n",
    "        if upy == -1 :\n",
    "            continue\n",
    "        mup = max(upy-size,0)\n",
    "        mdown = min(downy+size,mask.shape[0])\n",
    "        mask.T[i][mup:upy] = True     #위로 쭉\n",
    "        mask.T[i][downy:mdown] = True #아래로 쭉\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[126.6035, 251.1083],\n",
      "        [244.8977, 157.8127]])\n",
      "tensor([[459.8291, 338.9731],\n",
      "        [480.0000, 413.6379]])\n"
     ]
    }
   ],
   "source": [
    "# 박스 합치기!\n",
    "print(boxes[conlist].T[0:2])\n",
    "print(boxes[conlist].T[2:])\n",
    "tmps = torch.min(boxes[conlist].T[0:2],axis = 1)\n",
    "tmpd = torch.max(boxes[conlist].T[2:],axis = 1)\n",
    "\n",
    "X_S,Y_S=tmps.values\n",
    "X_D,Y_D=tmpd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask 합치기! \n",
    "conlist_masks = masks[conlist]\n",
    "combinMask = conlist_masks[0].clone()\n",
    "conlist_mask = torch.where(conlist_masks == True)\n",
    "combinMask[conlist_mask[1:]] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etim = torch.from_numpy(im.copy())\n",
    "emask = expand(combinMask,20,Y_S,Y_D,X_S,X_D)\n",
    "ebe = torch.where(emask!=True)\n",
    "etim[ebe] = 224\n",
    "etim = etim.numpy()\n",
    "etim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배경자르기..\n",
    "cv2.imshow('result',imageTool.fitsize(im,Y_S,Y_D,X_S,X_D))\n",
    "cv2.imshow('mask',etim)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "detectron2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
